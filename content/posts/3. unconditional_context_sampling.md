title: Robust Conditional Context Sampling with Unconditional Diffusion Models  
date: 2024-12-01 11:48
category: machine learning
tags: machine learning, deep generative models, diffusion, conditional sampling
slug: unconditional_context-sampling
summary: This blog post presents an interesting phenomenom that occurs in unconditional diffusion models used for inverse problem solving: a robustness to perturbations and noise to the input contexts. We claim that this phenomenom occurs due to the noisy context seen *during* training and show the results of some experiments on simple numerical trajectory examples that help justify this claim. 
status: published

*Estimated Reading Time: 20 minutes*

Diffusion models [3,7,8,10] have emerged as a flexible and expressive family of generative models, capable of producing high quality results in multiple domains, 
including images [2], audio [6], and video [5]. In
recent diffusion models, it has also become increasingly common to generate low-temperature samples by conditioning on class labels, either through an external
classifier [2] or by training on paired data and periodically discarding the class
labels [4]. Of particular interest is the idea of \textit{imputation}, or conditioning on partial data that has been generated 
beforehand. 

For example, in the context of videos, one can try to generate a 24 frame video conditioning based on a ground truth 16 frames that
has already been generated. Such an imputation scheme can then be used to say, extend the video autoregressively by repeatedly 
applying the imputation scheme through a sliding window conditioning on previous context frames. As another example, one can apply such a
scheme on images, generated pixels autoregressively based on images that you have already generated (or generating intermediate pixels for an higher-resolution image 
based on lower-resolution generated pixels).

 <figure markdown="span">
    <img src="/images/3.unconditional_context_sampling/conditional_diffusion.png" alt = "Diagram of conditioanl diffusion" style="width: 60%;"/>
    <figcaption style="text-align: center;"> Fig 1: The traditional conditional diffusion framework</ficaption>
</figure>

## Conditional Generation on Context
Multiple different approaches can be taken to do this conditional generation. This includes:

* Training a classifier-free (conditional) diffusion model [4] directly using previously generated context as conditioning input. This idea
    is also the basis of a follow up work of [1] (to be released soon).
   
* [10] proposes a general method for conditional sampling from a jointly trained unconditional diffusion model $p(\textbf{x}=[\textbf{x}^{a},\textbf{x}^b])$ (where 
    $\textbf{x}^a$ is the first half and $\textbf{x}^b$ is the second half) by diffusing 
    a noisy data point $\textbf{x}_t $ by replacing the first half of the reconstructed $\hat{x}_0 $ in a DDIM [8] step with the ground truth (generated) $\hat{x}^a $. The samples $\hat{x}^{a}_{t-1}$ will then have the correct marginals and 
    will conform to the ground truth $\hat{x}^{a}$. This method, however, has shown to be flawed due to the update not including
    a gradient term that would be required for a correct update: 
    $$
    \mathbb{E}_q[\textbf{x}^{b}|\textbf{x}_t,\textbf{x}^a] = 
    \mathbb{E}|_q[\textbf{x}^b|\textbf{x}_t] + (\sigma_t^2/\alpha_t)
    \nabla_{\textbf{x}^b_t}\log q(\textbf{x}^a|\textbf{x}_t)
    $$
    They thus propose to approximate the term inside the gradient 
    through a Taylor approximation giving a simple Gaussian: 
    $$q(\textbf{x}^a|\textbf{x}_t) \approx \mathcal{N}[\hat{\textbf{x}}^a_\theta(\textbf{x}_t),(\sigma_t^2/\alpha_t^2)\textbf{I})]$$. 

 <figure markdown="span">
    <img src="/images/3.unconditional_context_sampling/naive_rollout.png" alt = "Naive Rollout Using Context" style="width: 100%;"/>
    <figcaption style="text-align: center;"> Fig 2: A naive rollout of a conditional diffusion model can not generate past baselines due to out of 
    distribution contexts</ficaption>
</figure>

Both of the above methods, however, have their own flaws: the first can be shown to not be robust to out of distribution contexts. This 
can be problematic for domains such as videos, where when extending past baselines, the context will generally be out of distribution. 

The second method can also fail due to the approximation of $q(\textbf{x}^a, \textbf{x}_t)$ as a single unimodal Gaussian and the fixed size of $t$.
Although such an approach can be made asymptotically exact using more sophisticated approximation methods (such as particle filters, see [9]), 
such methods are generally computationally prohibtive on most practical use cases. 

Even with these course apprpoximations, however, the second approach appears to show some interesting generalization properties which we cover
in this blog post, namely a degree of robustness to out of distribution contexts. In this blog post, we give some intuition as to why this phenomenom
might occur by proposing that unconditional diffusion models see *noisy* context as well as clean context during training which leads to this degree
of robustness to noise. We justify this finding by comparing it with augmented conditional diffusion sampling, and we show that these two approaches 
are in fact, functionally equivalent.

## Conditioning on Context using an Unconditional Diffusion Sampler

We take 

## References

[1] Boyuan Chen, Diego Marti Monso, Yilun Du, Max Simchowitz, Russ Tedrake, and Vincent
Sitzmann. Diffusion forcing: Next-token prediction meets full-sequence diffusion, 2024.

[2] Prafulla Dhariwal and Alex Nichol. Diffusion models beat gans on image synthesis, 2021.

[3] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models, 2020.

[4] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance, 2022.

[5] Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and
David J. Fleet. Video diffusion models, 2022.

[6] Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. Diffwave: A versatile
diffusion model for audio synthesis, 2021.

[7] Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsu-
pervised learning using nonequilibrium thermodynamics, 2015.

[8] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models, 2022.

[9] Luhuan Wu, Brian L. Trippe, Christian A. Naesseth, David M. Blei, and John P. Cunningham.
Practical and Asymptotically Exact Conditional Sampling in Diffusion Models, 2023

[10] Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and
Ben Poole. Score-based generative modeling through stochastic differential equations, 2021.